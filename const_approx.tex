\subsection{Mean and variance}
Firstly, we will set out to arrive at an expression for the mean, and variance of the normal distributions to a constant value. By virtue of the Rayleigh fading assumption, we can note that the various channel vectors are statistically independent of each other and identically distributed (iid). Therefore, each of the normal random variables are the same in distribution, therefore, if the mean and variance are estimated for one of the groups, such an estimate will hold for all other groups. Thus, the constant mean and variance assumptions associated with Eq. (\ref{eq:pdf_max}) are satisfied.

\subsubsection{Empirical estimation approach}
An estimate of the mean and variance can be generated by calculating the arithmetic mean and variance, which will converge to the statistical mean and variance assuming a sufficiently large number of realizations are taken, by the weak law of large numbers. Therefore, the estimates of mean and variance are, respectively,:
\begin{equation}\label{eq:arith_mean_var}
    \begin{aligned}
        \mu &\approx \frac{1}{K}\sum_{k=1}^{K}c_k,\\
        \sigma^2 &\approx \frac{1}{K}\sum_{k=1}^{K}(c_k-\mu)^2 \ .
    \end{aligned}
\end{equation}
Where $c_k$ are realizations or samples of any of the various groups. Also, the error in this approximation will approach zero as $K\rightarrow\infty$.

This method is computationally expensive. Each iteration of the sum requires a sample from each of the $l$ user channels, not to mention the various operations required to calculate sum rate from each of these channel samples. Moreover, estimation of these statistics is entirely empirical in nature, the values of which depend entirely on the experiment at hand. Motivated by avoiding the relative intensity of computation, and the weakness of empirical dependence associated with this approach, an alternative method will be pursued.

\subsubsection{Analytic approach}
Motivated by reducing complexity and dependence on experiments associated with the previous empirical approach, we consider an analytic approach taken by Feng et al. \cite{Feng2014}. In this approach, an expression for the probability distribution of the SINR and mean sum rate in the MRTBF case is developed.

The expression for the PDF of the MRTBF SINR under uniform allocation of transmit power is given by:
\begin{equation}
    \begin{aligned}\label{eq:sinr_pdf}
        f_{\small{SINR}}(\gamma) &= C_\gamma \int_0^{\frac{1}{\gamma}}\frac{(\gamma^{-1}-\nu)^{(l-2)}\exp{(N\nu-\frac{N\sigma_n^2}{P}\nu^{-1})}}{\nu^{N+1}}d\nu \ ,\\
        where:\\
        C_\gamma &= \frac{\sigma_n^{2N}N^{l+N-1}\exp{(\frac{-N}{\gamma})}}{(P)^{N}\Gamma(N)\Gamma(l-1)\gamma^2} \ .
    \end{aligned}
\end{equation}
Note that $\Gamma(\cdot)$ is the gamma function in this expression. A more detailed derivation of this expression is given in Appendix A.

Therefore, the mean and variance of the sum rate can be expressed, respectively, as
\begin{equation}\label{eq:mean_var}
    \begin{aligned}
        \mu &= l \int_0^\infty \log_2(1+\gamma)f_{\small{SINR}}(\gamma)d\gamma \ , \\
        \sigma^2 &= l \int_0^\infty \log_2(1+\gamma)^2f_{\small{SINR}}(\gamma)d\gamma
    \end{aligned}
\end{equation}

The analytic closed form of the integrals given in Eqs. (\ref{eq:sinr_pdf},\ref{eq:mean_var}) is difficult to find. Therefore, a numerical approach will be taken towards solving these integrals. Note that if we have an expression for $f_{SINR}$, the integrals approximating the mean and variance in Eq. (\ref{eq:mean_var}) can be approximated by summing Monte Carlo trials. If we assume that values of $\gamma_{m}$ are sampled independently from the PDF $f_{SINR}$, then the mean and variance can be approximated as:
\begin{equation}\label{eq:mean_var_approx}
    \begin{aligned}
        \mu &\approx \frac{l}{M} \sum_{m=1}^M \log_2(1+\gamma_m)\ , \\
        \sigma^2 &\approx \frac{l}{M} \sum_{m=1}^M \log_2(1+\gamma_m)^2\ .
    \end{aligned}
\end{equation}
Moreover, as $M\rightarrow\infty$, the error in these approximations approaches zero.
\subsection{Correlation}
Secondly, we must approximate the correlation coefficient between each of the groups. In contrast to the mean and variance of these normal distributions, the correlation will not be the same for each group. This can be observed by first noting that the amount of correlation between these variables is directly proportional to the number of user common between two groups, then realizing that the various groups of users will not necessarily have the same number of users in common. For example, group A and group B may have two users in common, while group A and group C only have one user in common, etc.\\
\textbf{Claim:}\\ The correlation between two normal random variables representing group sum rate, $C_i,C_j$ is given by:
\begin{equation}\label{eq:overlap_corr}
    \begin{aligned}
        \rho_{corr}^{(i,j)} = \frac{u_{c}^{(i,j)}}{l}
    \end{aligned}
\end{equation}
where $u_{c}^{(i,j)}$ is the number of users common between groups $i,\ j$, and $l$ is the group size. \\
\textbf{Explanation:}\\ 
Firstly, observe that the sum rate is a sum of Shannon capacities as given by Eq. (\ref{eq:c_max}). We also know that the Shannon capacity for each users are mutually independent, since their channel vectors and SINRs are mutually independent.

Secondly, we note that calculation of correlation coefficient is a collection of linear operations. Thus, such an operation can be taken inside the sum to operate on the Shannon capacity terms.

We now note that the covariance between Shannon capacities of two users takes values of either $\frac{\sigma^2}{l}$, or $0$. The non-zero case occurs when the two users are, in fact, the same user: thus the covariance is simply the variance in the Shannon capacity. We know that the Shannon capacity distributions are iid, and the variance of these distributions is linearly related to the group size $l$ and the variance of the sum rate, $\sigma^2$. When calculating the correlation coefficient for the sum rate, the expression becomes a sum of these Shannon capacity covariance terms divided by the variance of the sum rate, $\sigma^2$. We can see the $\sigma^2$ terms cancel each-other off, and we arrive at the expression given in Eq. (\ref{eq:overlap_corr}).

The question now becomes, how to find some average value for $\rho_{corr}$ over the various pair-wise correlation coefficients terms, $\rho_{corr}^{(i,j)}$. We are interested in the average overlap between the $\binom{n}{l}$, groups. This average overlap calculation is symmetric for each user in the $\binom{n}{l}$ collection of $l$-tuples, therefore it can simply be calculated from the perspective of a single user:
\begin{equation}\label{eq:avg_corr}
    \begin{aligned}
        u_c = \frac{1}{\binom{n}{l}-1}\sum_{j=1\neq i}^{\binom{n}{l}}u_c^{(i,j)} \ .
    \end{aligned}
\end{equation}
As $n$ becomes sufficiently large with respect to $l$, this value will converge to a value of 1. Therefore, for $n$ sufficiently larger than $l$, we have
\begin{equation}\label{eq:const_corr}
    \begin{aligned}
        \rho_{corr} = \frac{1}{l} \ .
    \end{aligned}
\end{equation}